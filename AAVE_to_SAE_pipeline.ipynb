{"cells":[{"cell_type":"markdown","metadata":{"id":"GB0T9Su0DDzH"},"source":["## AAVE translation task"]},{"cell_type":"markdown","metadata":{"id":"jZovzJVofDu5"},"source":["#Drive Mounting"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tmjoiLDeZlK9","executionInfo":{"status":"ok","timestamp":1757999168852,"user_tz":420,"elapsed":0,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}},"colab":{"base_uri":"https://localhost:8080/","height":52,"referenced_widgets":["c274575d747d441dbb2f5acd332b8384"]},"outputId":"0dbaca67-9f4d-4122-c3b7-0ae98f467a87"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c274575d747d441dbb2f5acd332b8384","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import login\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/drive/Shareddrives/Algoverse_KSAC/hf_cache\" #stores model\n","os.environ[\"HF_HOME\"] = \"/content/drive/Shareddrives/Algoverse_KSAC/hf_home\"  # stores logins\n","\n","# hf_token = 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\n","\n","login()\n"]},{"cell_type":"markdown","metadata":{"id":"Y_Iv188ae__j"},"source":["#Model Loading (DO NOT RUN)\n","\n","If model has already been downloaded, run \"Model Reloading\" below instead."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nRNmtC0iv5cB"},"outputs":[],"source":["# from transformers import AutoTokenizer, AutoModelForCausalLM\n","# import os\n","\n","# model_id = \"Qwen/Qwen3-8B\"\n","# save_path = \"/content/drive/Shareddrives/Algoverse_KSAC/hf_models/Qwen/Qwen3-8B\"\n","# os.makedirs(save_path, exist_ok=True)\n","\n","# # Download from hub\n","# tokenizer = AutoTokenizer.from_pretrained(model_id)\n","# model = AutoModelForCausalLM.from_pretrained(\n","#     model_id,\n","#     dtype=\"auto\", #For weight loading\n","#     device_map=\"auto\"\n","# )\n","\n","# # Save tokenizer + model as a single file\n","# tokenizer.save_pretrained(save_path)\n","# model.save_pretrained(\n","#     save_path,\n","#     safe_serialization=True, #Using .safetensors\n","# )\n","\n","# print(\"Model and tokenizer saved into:\", save_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":127,"status":"ok","timestamp":1757997236075,"user":{"displayName":"Aaron Reed","userId":"01674140351048499516"},"user_tz":420},"id":"xuOBsODq5poX","outputId":"322329ab-0db3-4747-dcd2-63127ee0bd97","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU memory should now be purged.\n","Tue Sep 16 04:33:56 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["# Run this cell to purge GPU memory\n","\n","import gc\n","import torch\n","\n","# Delete model and tokenizer objects\n","try:\n","  del model\n","except:\n","  pass\n","\n","try:\n","  del tokenizer\n","except:\n","  pass\n","\n","# Run Python's garbage collector\n","gc.collect()\n","\n","# Clear CUDA cache\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","print(\"GPU memory should now be purged.\")\n","\n","# Verify\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"tCUoF7IqHUou"},"source":["#Model Reloading\n","\n","Load model from `save_path`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["e5cd8d18a7164378b5a5c7efae400eb1","e14b3f7cfa87422fbddad20d4b55d80c","325b883264cb44638d780338b1bd4a09","b3dd2ac7baf742e681c2fd1a673ea2a5","1b360fcd0b314b0b8db7f300fc25d329","cef4e8b6ffb34e119845b4a1da1456b7","0297d8d3ca2844c29edc74b3aa8e73de","d439a2c791e04572b29105d33ec09c3d","33fa48a9a84c4dd6bdde1d9159a65f5a","cbec4daeca3440bfb9b14c76b933bfec","45b1911ed6df4109b1a6588eef0c4552"]},"executionInfo":{"elapsed":251054,"status":"ok","timestamp":1757997518525,"user":{"displayName":"Aaron Reed","userId":"01674140351048499516"},"user_tz":420},"id":"A8BJpw9ze_CQ","outputId":"752e3e6e-5ac9-409e-fb5f-e11dfa06956d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5cd8d18a7164378b5a5c7efae400eb1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"]},{"output_type":"stream","name":"stdout","text":["Reloaded model successfully\n","model.device = cuda:0\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","save_path = \"/content/drive/Shareddrives/Algoverse_KSAC/hf_models/Qwen/Qwen3-8B\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(save_path, local_files_only=True)\n","model = AutoModelForCausalLM.from_pretrained(\n","    save_path,\n","    local_files_only=True,\n","    dtype=\"auto\",\n","    device_map=\"auto\"\n",")\n","\n","print(\"Reloaded model successfully\")\n","print(f\"model.device = {model.device}\") #Verifying device\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ef8707ad","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757731671195,"user_tz":420,"elapsed":235,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}},"outputId":"95e5bb9f-e7af-4191-c258-e87c67c1ed1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU memory should now be purged.\n","Sat Sep 13 02:47:50 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n","| N/A   32C    P0             61W /  400W |   60779MiB /  81920MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["# Run this cell to purge GPU memory\n","\n","import gc\n","import torch\n","\n","# Delete model and tokenizer objects\n","try:\n","  del model\n","except:\n","  pass\n","\n","try:\n","  del tokenizer\n","except:\n","  pass\n","\n","# Run Python's garbage collector\n","gc.collect()\n","\n","# Clear CUDA cache\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","print(\"GPU memory should now be purged.\")\n","\n","# Verify\n","!nvidia-smi"]},{"cell_type":"markdown","source":["#Data Loading"],"metadata":{"id":"ukt0YQlXA0P_"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","from google.colab import files"],"metadata":{"id":"t1NM46KAA5_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pJB3_SU4h9Od"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use this cell to upload files from your local computer to the `/content/` directory in this Colab's volume.\n","uploaded = files.upload()"],"metadata":{"id":"02JqmZxsA6Rb","colab":{"base_uri":"https://localhost:8080/","height":39},"executionInfo":{"status":"ok","timestamp":1757997772103,"user_tz":420,"elapsed":2660,"user":{"displayName":"Aaron Reed","userId":"01674140351048499516"}},"outputId":"08191f02-06ab-4ae9-8593-8bb733548ce7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-d224dd88-1d97-4351-bd0e-6fd4dbb81c86\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d224dd88-1d97-4351-bd0e-6fd4dbb81c86\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load\n","filename = \"/content/drive/Shareddrives/Algoverse_KSAC/dilemma_ab_aave_only_v2.csv\"\n","df = pd.read_csv(filename)\n","\n","df.columns = [c.strip().lower() for c in df.columns]\n","\n","breakpoint()\n","# Preprocessing: drop 'label, 'type', 'language' columns\n","\n","# Ensure expected fields exist / are derived\n","if \"answer_count\" not in df.columns and \"answers\" in df.columns:\n","    df[\"answer_count\"] = df[\"answers\"].apply(lambda x: len(x) if isinstance(x, list) else 0)\n","\n","# Clean values\n","def yes_no(v):\n","    s = str(v).strip().lower()\n","    return \"Yes\" if s in {\"yes\", \"y\", \"true\", \"1\"} or v is True else \"No\"\n","\n","if \"label\" in df.columns:\n","    df[\"label\"] = df[\"label\"].apply(yes_no)\n","\n","# Rename to organized headers\n","df = df.rename(columns={\n","    \"qid\": \"QID\",\n","    \"question\": \"Question\",\n","    \"answer_count\": \"Answer Count\",\n","    \"label\": \"Label\",\n","    \"type\": \"Type\",\n","    \"lang\": \"Language\"\n","})\n","\n","# Reorder\n","cols = [c for c in [\"QID\",\"Question\",\"Answer Count\",\"Label\",\"Type\",\"Language\"] if c in df.columns]\n","if \"answers\" in df.columns:\n","    cols += [\"answers\"]\n","df = df[cols].reset_index(drop=True)\n","\n","# Make .head() look normal and organized\n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.width\", 160)\n","pd.set_option(\"display.max_colwidth\", 120)\n","\n","\n","df[\"Question\"][0:50]\n","\n","data_list = df[\"Question\"].to_list()\n"],"metadata":{"id":"yOib3IjABCUC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1757998467297,"user_tz":420,"elapsed":71464,"user":{"displayName":"Aaron Reed","userId":"01674140351048499516"}},"outputId":"5f3bbfa5-cd78-4753-ce27-22bfd8cf67b7"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["--Return--\n","None\n","> \u001b[0;32m/tmp/ipython-input-1347438768.py\u001b[0m(9)\u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m      7 \u001b[0;31m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m      8 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m----> 9 \u001b[0;31m\u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     10 \u001b[0;31m\u001b[0;31m# Preprocessing: drop 'label' and 'language' columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m     11 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","ipdb> sum(df['type'] == 'answerable')\n","3330\n","ipdb> q\n"]}]},{"cell_type":"markdown","source":["#Running Inference"],"metadata":{"id":"66PXzLyqA38N"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYDNAbrCbtfk"},"outputs":[],"source":["# from transformers import pipeline\n","from transformers.generation.utils import GenerationMixin\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33332,"status":"ok","timestamp":1757814211758,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"},"user_tz":420},"id":"Rbkewud1bi6a","outputId":"2e8568ac-9c33-474f-95d5-fdc8327453b9"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["What work, tradition or theory does Spaceballs reference, review article or Star Trek: The Original Series?  \n","What work, tradition or theory does Bullet Train reference, Thomas & Friends or nonlinear gameplay?  \n","What work, tradition or theory does Q Who reference, Authors of Plant Names or photon?  \n","What work, tradition or theory does The Tin Drum reference, Book of Genesis or Trouton's rule?  \n","What work, tradition or theory does Back to the Future Part III reference, A Fistful of Dollars or genealogy?  \n","What is the dominant foot or preferred stance for Joseba Zaldua, left-footedness or right-footedness?  \n","What is the dominant foot or preferred stance for Iker Begoña, right-footedness or ambidexterity?  \n","What is the dominant foot or preferred stance for Jon Ander Garrido, right-footedness or ambidexterity?  \n","What is the dominant foot or preferred stance for Unai Marrero, right-footedness or left-footedness?  \n","Where was Ahwak recorded, Olympic Studios or Abbey Road Studios?  \n","Where was The Snow Queen recorded, Õru or Tallinn?  \n","Where was The Lost Treasure for Aquila recorded, Brač or Takarajima?  \n","Where was Hinatazaka de Aimashō recorded, Television City or Tokyo Media City?  \n","Where was Soundtrack recorded, Fullerton College or Lassen Community College?  \n","What is the tempo marking for Beauty and the Beast, guitar solo or andante?  \n","What is the tempo marking for We No Speak Americano, alla breve or duple or quadruple meter?  \n","What is the tempo marking for Baa, Baa, Black Sheep, overtone or moderato?  \n","Under what copyright license was MuLinux released, GNU General Public License or firearms license?  \n","Under what copyright license was KDE Education Project released, GNU General Public License or licence to crenellate?  \n","Under what copyright license was GNU released, GNU Lesser General Public License or Network Access License?  \n","Under what copyright license was Apache Hadoop released, Apache License, Version 2.0 or Creative Commons Attribution-ShareAlike?  \n","Under what copyright license was Slackware released, GNU General Public License or licence to crenellate?  \n","What season is for a series Don't Ever Change, House, season 4 or Defiance, season 1?  \n","What season is for a series Need to Know, House, season 2 or Two and a Half Men, season 5?  \n","What season is for a series Death Has a Shadow, Family Guy, season 1 or Kodoku no Gourmet, season 8?  \n","What season is for a series Everybody Dies, Gossip Girl, season 6 or House, season 8?  \n","What season is for a series Three Stories, Talang 2021 or House, season 1?  \n","What is the historic county for Guisborough, Yorkshire or Brecknockshire?  \n","What is the historic county for Crucible Theatre, County Limerick or Yorkshire?  \n","What is the historic county for City Square, County Fermanagh or Yorkshire?\n"]}],"source":["# Inference on already-loaded model\n","\n","messages = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": (\n","\n","    \"You are a strict translation engine.\"\n","    \"You MUST only output the translated SAE (Standard American English) questions.\"\n","    \"Do not explain, do not reason, do not add tags or extra text.\"\n","    \"Only return the final grammatically correct questions, nothing else.\"\n","\n","\n","        \"Examples:\\n\"\n","        \"AAVE: Who be Einstein's ol' lady?\\n\"\n","        \"SAE: Who was Einstein's wife?\\n\\n\"\n","        \"AAVE: When Obama come in the world?\\n\"\n","        \"SAE: When was Obama born?\\n\\n\"\n","        \"AAVE: Where King Jr. do that 'I got a dream' speech at?\\n\"\n","        \"SAE: Where did Martin Luther King Jr. give his 'I Have a Dream' speech?\\n\\n\"\n","        \"AAVE: What year Mandela start runnin' South Africa, and how long he stay holdin' that seat?\\n\"\n","        \"SAE: In what year did Mandela become the President of South Africa, and how long did he remain in office?\\n\\n\"\n","        \"Remember: ONLY output the translated SAE questions, line by line, with no commentary.\"\n","        ),\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": f\"Transform these incomplete questions into complete, grammatically perfect SAE. {' '.join(data_list[:30])}\"  #Joining a list into a string\n","\n","    }\n","]\n","\n","\n","\n","\n","inputs = tokenizer.apply_chat_template(\n","        messages,\n","        add_generation_prompt=True,\n","        tokenize=True,\n","        return_dict=True,\n","        return_tensors=\"pt\",\n","        enable_thinking = False\n",").to(model.device)\n","\n","\n","outputs = model.generate(**inputs, max_new_tokens=2600, do_sample=False, temperature=0) #Increasing the temperature, and only considering tokens that make up 90% of probability (p = prob)\n","\n","#\n","\n","\n","output_answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True) # Slicing the length of the input tokens to get what comes after (Getting the length) (start:end)\n","\n","\n","\n","print(output_answer)"]},{"cell_type":"markdown","metadata":{"id":"794AzartKrb8"},"source":["#Input/Output cleaning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1757814221563,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"},"user_tz":420},"id":"D9mFJxLAIJT6","outputId":"3890f067-cfa2-46d2-9c89-1470c194cfff"},"outputs":[{"output_type":"stream","name":"stdout","text":["['What work, tradition or theory spaceballs reference, review article or star trek: the original series?', 'What work, tradition or theory bullet train reference, thomas & friends or nonlinear gameplay?', 'What work, tradition or theory q who reference, authors of plant names or photon?', \"What work, tradition or theory the tin drum reference, book of genesis or trouton's rule?\", 'What work, tradition or theory back to the future part iii reference, a fistful of dollars or genealogy?', 'What the dominant foot or preferred stance for joseba zaldua, left-footedness or right-footedness?', 'What the dominant foot or preferred stance for iker begoña, right-footedness or ambidexterity?', 'What the dominant foot or preferred stance for jon ander garrido, right-footedness or ambidexterity?', 'What the dominant foot or preferred stance for unai marrero, right-footedness or left-footedness?', 'Where ahwak recorded, olympic studios or abbey road studios?', 'Where the snow queen recorded, õru or tallinn?', 'Where the lost treasure for aquila recorded, brač or takarajima?', 'Where hinatazaka de aimashō recorded, television city or tokyo media city?', 'Where soundtrack recorded, fullerton college or lassen community college?', 'What the tempo marking for beauty and the beast, guitar solo or andante?', 'What the tempo marking for we no speak americano, alla breve or duple or quadruple meter?', 'What the tempo marking for baa, baa, black sheep, overtone or moderato?', 'Under what copyright license mulinux released, gnu general public license or firearms license?', 'Under what copyright license kde education project released, gnu general public license or licence to crenellate?', 'Under what copyright license gnu released, gnu lesser general public license or network access license?', 'Under what copyright license apache hadoop released, apache license, version 2.0 or creative commons attribution-sharealike?', 'Under what copyright license slackware released, gnu general public license or licence to crenellate?', \"What season for a series don't ever change, house, season 4 or defiance, season 1?\", 'What season for a series need to know, house, season 2 or two and a half men, season 5?', 'What season for a series death has a shadow, family guy, season 1 or kodoku no gourmet, season 8?', 'What season for a series everybody dies, gossip girl, season 6 or house, season 8?', 'What season for a series three stories, talang 2021 or house, season 1?', 'What the historic county for guisborough, yorkshire or brecknockshire?', 'What the historic county for crucible theatre, county limerick or yorkshire?', 'What the historic county for city square, county fermanagh or yorkshire?']\n"]}],"source":["# Extract AAVE input\n","input = ' '.join(data_list[:30])\n","\n","def extract_input(input):\n","  questions = [q.strip().capitalize() + \"?\" for q in input.split(\"?\") if q.strip()]\n","\n","  return questions\n","\n","\n","inputs = extract_input(input)\n","print(inputs)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1757814233017,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"},"user_tz":420},"id":"jYNYnLA3_uNE","outputId":"e9d112f5-8f6f-4284-f4a6-1d9f7f95a162"},"outputs":[{"output_type":"stream","name":"stdout","text":["['What work, tradition or theory does Spaceballs reference, review article or Star Trek: The Original Series?', 'What work, tradition or theory does Bullet Train reference, Thomas & Friends or nonlinear gameplay?', 'What work, tradition or theory does Q Who reference, Authors of Plant Names or photon?', \"What work, tradition or theory does The Tin Drum reference, Book of Genesis or Trouton's rule?\", 'What work, tradition or theory does Back to the Future Part III reference, A Fistful of Dollars or genealogy?', 'What is the dominant foot or preferred stance for Joseba Zaldua, left-footedness or right-footedness?', 'What is the dominant foot or preferred stance for Iker Begoña, right-footedness or ambidexterity?', 'What is the dominant foot or preferred stance for Jon Ander Garrido, right-footedness or ambidexterity?', 'What is the dominant foot or preferred stance for Unai Marrero, right-footedness or left-footedness?', 'Where was Ahwak recorded, Olympic Studios or Abbey Road Studios?', 'Where was The Snow Queen recorded, Õru or Tallinn?', 'Where was The Lost Treasure for Aquila recorded, Brač or Takarajima?', 'Where was Hinatazaka de Aimashō recorded, Television City or Tokyo Media City?', 'Where was Soundtrack recorded, Fullerton College or Lassen Community College?', 'What is the tempo marking for Beauty and the Beast, guitar solo or andante?', 'What is the tempo marking for We No Speak Americano, alla breve or duple or quadruple meter?', 'What is the tempo marking for Baa, Baa, Black Sheep, overtone or moderato?', 'Under what copyright license was MuLinux released, GNU General Public License or firearms license?', 'Under what copyright license was KDE Education Project released, GNU General Public License or licence to crenellate?', 'Under what copyright license was GNU released, GNU Lesser General Public License or Network Access License?', 'Under what copyright license was Apache Hadoop released, Apache License, Version 2.0 or Creative Commons Attribution-ShareAlike?', 'Under what copyright license was Slackware released, GNU General Public License or licence to crenellate?', \"What season is for a series Don't Ever Change, House, season 4 or Defiance, season 1?\", 'What season is for a series Need to Know, House, season 2 or Two and a Half Men, season 5?', 'What season is for a series Death Has a Shadow, Family Guy, season 1 or Kodoku no Gourmet, season 8?', 'What season is for a series Everybody Dies, Gossip Girl, season 6 or House, season 8?', 'What season is for a series Three Stories, Talang 2021 or House, season 1?', 'What is the historic county for Guisborough, Yorkshire or Brecknockshire?', 'What is the historic county for Crucible Theatre, County Limerick or Yorkshire?', 'What is the historic county for City Square, County Fermanagh or Yorkshire?']\n"]}],"source":["# Extract SAE output\n","\n","def extract_output(output_answer):\n","  questions = [q.strip() + \"?\" for q in output_answer.split(\"?\") if q.strip()]\n","\n","  questions_lower = [q.lower() for q in questions]\n","  return questions\n","\n","outputs = extract_output(output_answer)\n","print(outputs)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ftjpp9GIf2Zn"},"source":["#Bart Score evaluation (WIP)"]},{"cell_type":"code","source":["import sys\n","import numpy as np"],"metadata":{"id":"67qPJwhblBQi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Install BLEURT first"],"metadata":{"id":"81vlqjYajMcg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YPeZln1Vf7ME","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6aa47b6a-cb6d-42c0-ff4d-f88d4d81b474","executionInfo":{"status":"ok","timestamp":1757814366169,"user_tz":420,"elapsed":120982,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'bleurt'...\n","remote: Enumerating objects: 134, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (18/18), done.\u001b[K\n","remote: Total 134 (delta 0), reused 17 (delta 0), pack-reused 116 (from 1)\u001b[K\n","Receiving objects: 100% (134/134), 31.28 MiB | 38.82 MiB/s, done.\n","Resolving deltas: 100% (49/49), done.\n","Processing /content/bleurt\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (1.16.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (2.19.0)\n","Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (1.1.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from BLEURT==0.0.2) (0.2.1)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->BLEURT==0.0.2) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->BLEURT==0.0.2) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->BLEURT==0.0.2) (2025.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (1.74.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.10.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (3.14.0)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->BLEURT==0.0.2) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2025.8.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->BLEURT==0.0.2) (3.9)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->BLEURT==0.0.2) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->BLEURT==0.0.2) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->BLEURT==0.0.2) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->BLEURT==0.0.2) (0.1.2)\n","Building wheels for collected packages: BLEURT\n","  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456766 sha256=dc61859dcb845a3443cd691ee7833498bfadfe08ae686f1ed1b64c810c5c482a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ivoh_cpi/wheels/27/29/e7/dd83f91837d3166c90e8f10b032d942ee54bc533fc36c98ecb\n","Successfully built BLEURT\n","Installing collected packages: BLEURT\n","Successfully installed BLEURT-0.0.2\n","--2025-09-14 01:44:22--  https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.207, 108.177.127.207, 172.217.218.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2140294207 (2.0G) [application/octet-stream]\n","Saving to: ‘BLEURT-20.zip’\n","\n","BLEURT-20.zip       100%[===================>]   1.99G  25.8MB/s    in 80s     \n","\n","2025-09-14 01:45:42 (25.6 MB/s) - ‘BLEURT-20.zip’ saved [2140294207/2140294207]\n","\n","Archive:  BLEURT-20.zip\n","   creating: BLEURT-20/\n","  inflating: BLEURT-20/bert_config.json  \n","  inflating: BLEURT-20/saved_model.pb  \n","   creating: BLEURT-20/variables/\n","  inflating: BLEURT-20/variables/variables.index  \n","  inflating: BLEURT-20/variables/variables.data-00000-of-00001  \n","  inflating: BLEURT-20/sent_piece.vocab  \n","  inflating: BLEURT-20/bleurt_config.json  \n","  inflating: BLEURT-20/sent_piece.model  \n"]}],"source":["!pip install tensorflow>=2.3.0\n","!pip install tensorflow-text>=2.3.0\n","!git clone https://github.com/google-research/bleurt.git\n","!cd bleurt && python -m pip install .\n","sys.path.append('/content/bleurt')\n","!wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip\n","!unzip BLEURT-20.zip\n","\n"]},{"cell_type":"markdown","source":["Install BARTScore"],"metadata":{"id":"lRWips69jY5X"}},{"cell_type":"code","source":["\n","!git clone -q https://github.com/neulab/BARTScore.git\n","sys.path.append(\"/content/BARTScore\")\n","!pip -q install \"transformers>=4.40,<4.47\" sentencepiece accelerate torch tqdm --upgrade\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdHesAeEjctS","executionInfo":{"status":"ok","timestamp":1757814403393,"user_tz":420,"elapsed":18552,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}},"outputId":"6e13f59b-770f-43c9-bb6a-ca48aabce92a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m111.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from bart_score import BARTScorer\n","from bleurt import score\n","\n"],"metadata":{"id":"LIDqLJBOWOzh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bart_scorer = BARTScorer(device='cuda', checkpoint='facebook/bart-large')\n","bleurt_scorer = score.BleurtScorer(\"./BLEURT-20\")"],"metadata":{"id":"2dfXHcmJWSah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def evaluate_single_pair(inputs, outputs, reference_sae=None):\n","#     results = {}\n","\n","#     bart_score_forward = bart_scorer.score([aave_text], [sae_text], batch_size=1)[0] #Getting the correctness of the AAVE -> SAE translation\n","#     results['bart_score_forward'] = bart_score_forward\n","\n","#     bart_score_backward = bart_scorer.score([sae_text], [aave_text], batch_size=1)[0] #Referencing with the correctness of the SAE -> AAVE \"Does it map the same?\"\n","#     results['bart_score_backward'] = bart_score_backward\n","\n","#     if reference_sae is not None:\n","#       bart_score_ref = bart_scorer.score([reference_sae], [sae_text], batch_size=1)[0]\n","#       results['bart_score_ref'] = bart_score_ref\n","\n","\n","#     bleurt_score = bleurt_scorer.score(references = [aave_text], candidates = [sae_text])[0] #Comparing bart score with bluert score\n","#     results['bleurt_score'] = bleurt_score\n","\n","#     return results\n","\n","# #AAVE_Input = data_list[i] for i in data_list\n","# #AAVE_Input = \"what is the recommended unit of measurement for Blake number, numerical digit or 1\"\n","# #SAE_Output = output_answer\n","# SAE_Output = \"What unit you s’posed to use for the Blake number — a number digit or just 1?\"\n","\n","\n","# print(evaluate_single_pair(AAVE_Input, SAE_Output))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vAJ8Lx0mQ5Gb","executionInfo":{"status":"ok","timestamp":1757643679116,"user_tz":420,"elapsed":379,"user":{"displayName":"Saket sandru","userId":"16400379376334202121"}},"outputId":"5e852327-2538-45f2-da67-815a94b92079"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'bart_score_forward': -7.5764312744140625, 'bart_score_backward': -6.110034942626953, 'bleurt_score': 0.574549674987793}\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"9_9OekzwDTIn"}},{"cell_type":"code","source":[],"metadata":{"id":"Dd7fks647a9w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_multiple_pairs(inputs, outputs):\n","    if len(inputs) != len(outputs):\n","        raise ValueError(\"Lists must be the same length\")\n","\n","    results = []\n","\n","    for i in range(len(inputs)):\n","        aave_text = inputs[i]\n","        sae_text  = outputs[i]\n","\n","        pair_result = {\n","            \"index\": i,\n","            \"bart_score_backward\": bart_scorer.score([sae_text], [aave_text], batch_size=1)[0]\n","        }\n","\n","        results.append(pair_result)\n","\n","    return results\n","\n","\n","\n","\n","# AAVE phrasing\n","aave_questions = [\n","    inputs\n","]\n","\n","# SAE translations\n","sae_questions = [\n","   outputs\n","]\n","\n","bart_scores = evaluate_multiple_pairs(aave_questions, sae_questions)\n","\n","print(bart_scores)\n"],"metadata":{"id":"tU4jJT_rCGOD","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"error","timestamp":1757814507165,"user_tz":420,"elapsed":49,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}},"outputId":"7ba6e609-5fe2-4e4e-9031-81ac1c263a0e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-444510908.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m ]\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mbart_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_multiple_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maave_questions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msae_questions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbart_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-444510908.py\u001b[0m in \u001b[0;36mevaluate_multiple_pairs\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         pair_result = {\n\u001b[1;32m     12\u001b[0m             \u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;34m\"bart_score_backward\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbart_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msae_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maave_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         }\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/BARTScore/bart_score.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, srcs, tgts, batch_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     encoded_src = self.tokenizer(\n\u001b[0m\u001b[1;32m     39\u001b[0m                         \u001b[0msrc_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2909\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_max_length\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mLARGE_INTEGER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2911\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation_warnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Asking-to-truncate-to-max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2912\u001b[0m                             logger.warning(\n\u001b[1;32m   2913\u001b[0m                                 \u001b[0;34m\"Asking to truncate to max_length but no maximum length is provided and the model has\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2997\u001b[0m             \u001b[0;34m\"truncation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m             \u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2999\u001b[0;31m             \u001b[0;34m\"stride\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3000\u001b[0m             \u001b[0;34m\"is_split_into_words\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3001\u001b[0m             \u001b[0;34m\"pad_to_multiple_of\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3198\u001b[0m         padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n\u001b[1;32m   3199\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3200\u001b[0;31m             \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3201\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m             \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","source":["\n","    if reference_sae is not None:\n","      bart_score_ref = bart_scorer.score([reference_sae], [sae_text], batch_size=1)[0]\n","      results['bart_score_ref'] = bart_score_ref\n","\n","\n","    bleurt_score = bleurt_scorer.score(references = [aave_text], candidates = [sae_text])[0] #Comparing bart score with bluert score\n","    results['bleurt_score'] = bleurt_score\n","\n","    return results\n","\n","AAVE_Input = \"Who be the editor of Enneads and also act in The Sixth Sense?\"\n","\n","SAE_Output = \"Who was the editor of Enneads and also acted in The Sixth Sense?\"\n","\n","\n","\n","print(evaluate_single_pair(AAVE_Input, SAE_Output))"],"metadata":{"id":"2yoYt8Wz-lAV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Bleurt Score intepretation: Closer to 1 = higher quality"],"metadata":{"id":"BNObbueaqTBr"}},{"cell_type":"code","source":["\n","results = evaluate_single_pair(AAVE_Input, SAE_Output)\n","bart_score_forward = results['bart_score_forward']\n","bart_score_backward = results['bart_score_backward']\n","\n","\n","def quality_assesment(bart_score_forward, bart_score_backward):\n","    \"\"\"Deciding if the provided BART scores were good enough quality\"\"\"\n","\n","\n","    average_score = np.mean(bart_score_forward, bart_score_backward)\n","\n","    bart_threshold = -2.5  # We can change this later\n","\n","    if average_score > bart_threshold:\n","        quality_label = \"excellent\"\n","    elif bart_threshold < average_score < -2:\n","        quality_label = \"good\"\n","    else:\n","        quality_label = \"poor\"\n","\n","    return {\n","        'bart_average': average_score,\n","        'quality_label': quality_label,\n","    }\n","\n","print(quality_assesment(bart_score_forward, bart_score_backward))\n","\n","\n","#implement drive saving later\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRBHlideWrT9","executionInfo":{"status":"ok","timestamp":1757043250366,"user_tz":420,"elapsed":308,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}},"outputId":"1d391437-d8a1-4277-b379-338a024749d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'bart_average': -2.8464229106903076, 'quality_label': 'poor'}\n"]}]},{"cell_type":"code","source":["def find_problem_translations(results,bart_threshold = -1.5):\n","  problems = []\n","  for result in results:\n","    if result[\"bart_score\"] < bart_threshold:\n","      problems.append(result)\n","  return problems\n","\n","#implement drive saving later"],"metadata":{"id":"Xj6ke6osfxZJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This indicates that we may need to experiment with fine tuning"],"metadata":{"id":"ggix9g5NfRFn"}},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=\"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\")\n","\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": \"Evaluate the accuracy of the shown translation from AAVE to SAE. Do not provide a written explanation. Only provide a score from 0-100. If there is even any trace of missing semantic value, deduct from the total score\"},\n","\n","    {\"role\": \"user\", \"content\": \"Who be Einstein's ol' lady?\"},\n","    {\"role\": \"assistant\", \"content\": \"Who was Einstein's wife?\"},\n","\n","    {\"role\": \"user\", \"content\": \"When Obama come in the world?\"},\n","    {\"role\": \"assistant\", \"content\": \"When was Obama born?\"},\n","\n","    {\"role\": \"user\", \"content\": \"Where King Jr. do that 'I got a dream' speech at?\"},\n","    {\"role\": \"assistant\", \"content\": \"Where did Martin Luther King Jr. give his 'I Have a Dream' speech?\"},\n","\n","    {\"role\": \"user\", \"content\": \"What year Mandela start runnin’ South Africa, and how long he stay holdin’ that seat?\"},\n","    {\"role\": \"assistant\", \"content\": \"In what year did Mandela become the President of South Africa, and how long did he remain in office?\"},\n","\n","    #{\"role\": \"user\", \"content\": \"What spaceship took the first man round Earth, what his name was, and what year that go down?\"},\n","    #{\"role\": \"assistant\", \"content\": \"Which spacecraft carried the first human to orbit Earth, what was the astronaut’s name, and what year did this mission occur?\"},\n","\n","    {\"role\": \"user\", \"content\": \" AAVE: Who be the first man to step on the moon, and what year that happen? SAE: Who was the first man to step on the moon, and what year did he step on the moon?\"},\n","\n","]\n","\n","#\n","completion = client.chat.completions.create(\n","    model=\"gpt-4.1\",\n","    messages=messages,\n","    n=1,\n","    temperature=0\n",")\n","\n","score = completion.choices[0].message.content\n","print(score)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBHtwNybyR_-","executionInfo":{"status":"ok","timestamp":1757111193669,"user_tz":420,"elapsed":1011,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}},"outputId":"2c31a047-2c3d-4d6c-aa0a-c8bdfa777f6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100\n"]}]},{"cell_type":"markdown","source":["# Older code"],"metadata":{"id":"4cntmBPRyFc8"}},{"cell_type":"code","source":[],"metadata":{"id":"h-l3c0cFyHOh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"9wBi5-i_0Y8W"},"outputs":[],"source":["# # Skipping because all of this is installed later\n","\n","# !pip install openai\n","# !pip install -U transformers\n","# !pip uninstall -y transformers tokenizers huggingface-hub accelerate\n","# !pip cache purge\n","# # !pip install \"transformers\" \"accelerate>=0.29.0\"\n","# !pip install transformers[torch] accelerate\n","\n","# # for 8-bit inference\n","# !pip install bitsandbytes"]},{"cell_type":"markdown","metadata":{"id":"lXcCG0KRbX8o"},"source":["## GPT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG_xrl0L2q-t"},"outputs":[],"source":["# import openai\n","# from google.colab import userdata"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJ_oFumW3muU"},"outputs":[],"source":["# from openai import OpenAI\n","\n","# client = OpenAI(api_key=\"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\")\n","\n","\n","# messages = [\n","#     {\"role\": \"system\", \"content\": \"Translate the given AAVE questions to SAE. Keep all names and dates verbatim while preserving the meaning of the phrase.\"},\n","\n","#     {\"role\": \"user\", \"content\": \"Who be Einstein's ol' lady?\"},\n","#     {\"role\": \"assistant\", \"content\": \"Who was Einstein's wife?\"},\n","\n","#     {\"role\": \"user\", \"content\": \"When Obama come in the world?\"},\n","#     {\"role\": \"assistant\", \"content\": \"When was Obama born?\"},\n","\n","#     {\"role\": \"user\", \"content\": \"Where King Jr. do that 'I got a dream' speech at?\"},\n","#     {\"role\": \"assistant\", \"content\": \"Where did Martin Luther King Jr. give his 'I Have a Dream' speech?\"},\n","\n","#     {\"role\": \"user\", \"content\": \"What year Mandela start runnin’ South Africa, and how long he stay holdin’ that seat?\"},\n","#     {\"role\": \"assistant\", \"content\": \"In what year did Mandela become the President of South Africa, and how long did he remain in office?\"},\n","\n","#     #{\"role\": \"user\", \"content\": \"What spaceship took the first man round Earth, what his name was, and what year that go down?\"},\n","#     #{\"role\": \"assistant\", \"content\": \"Which spacecraft carried the first human to orbit Earth, what was the astronaut’s name, and what year did this mission occur?\"},\n","\n","#     {\"role\": \"user\", \"content\": \"What spaceship took the first man round Earth, what his name was, and what year that go down?\"}\n","# ]\n","\n","\n","# completion = client.chat.completions.create(\n","#     model=\"gpt-3.5-turbo\",\n","#     messages=messages,\n","#     n=1,\n","#     temperature=1.5\n","# )\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1757996850857,"user":{"displayName":"Aaron Reed","userId":"01674140351048499516"},"user_tz":420},"id":"CuhPlNLi9CWQ","outputId":"6af86224-a8ef-4ad9-f60b-7dc8f9653a0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["What spaceship took the first man round Earth, what his name was, and what year that go down?\n","What was the spacecraft that took the first man into orbit around Earth, what was his name, and in what year did this happen?\n"]}],"source":["# a = [m[\"content\"] for m in messages if m[\"role\"] == \"user\"][-1] #Takes the content of the last user message in the message dictionary\n","# print(a)\n","\n","# b = completion.choices[0].message.content\n","# print(b)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tLyfTpdBbb4K"},"source":["## LLama"]},{"cell_type":"markdown","metadata":{"id":"fhQWvwtNB1in"},"source":["## Sample workload"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4260,"status":"ok","timestamp":1757996956557,"user":{"displayName":"Aaron Reed","userId":"01674140351048499516"},"user_tz":420},"id":"OIfEO56ax2Pn","outputId":"96eb8951-c7d6-4870-daa0-343fc089f684"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","Tesla T4\n"]}],"source":["# Check that CUDA is available and what NVIDIA GPU we have\n","import torch\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1756699881891,"user":{"displayName":"Aaron Z Reed","userId":"01153015130621079093"},"user_tz":420},"id":"0s0fmuY_yEEY","outputId":"56070282-3bad-402a-c0d5-11fe3c20686b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Sep  1 04:11:21 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["# Ping the GPU\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":16362,"status":"ok","timestamp":1756699921175,"user":{"displayName":"Aaron Z Reed","userId":"01153015130621079093"},"user_tz":420},"id":"rhYQH6c10-1s","outputId":"265e739b-0f4c-479b-b5aa-248459451f8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.47.0\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.34.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n"]}],"source":["# for 8-bit inference\n","!pip install bitsandbytes\n","\n","# for GPU acceleration\n","!pip install accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":689,"referenced_widgets":["e8d19928c4424e218e235d46a9d95e22","49e82cf4035d44fea00a917d9a675547","d232660189254beba0d638b21a988f7c","da467badf3bd4787ab947e07e388ebdd","d0df6519f1814c9bb71581151b3a5782","264b4617ac3047febb9c61181e9a5f1d","40dc4e2c43644df4b906014df5b219d3","4bee7682c98341dd99e7c12b18f8d613","cf2fe47a2c6a4f988063ff54a3c073c4","16c1f2839fbf47db9ff23ae02eca20f2","8a75bdbf23024c159fb96e84d2adfcce","dd2d80e62ea144dbb77a1ad6e4fd3f43","4f42b25c86774cf8a783351bd34cee89","be13bb353c5c47418ce36b476e5cdb09","0b4b22c170514feb89959cc55a07bd76","a87b8c82126d467583058e95d78859d8","4aa90b6ee9b448cfa634cf49d92e3513","ba71a7ab4662410f92f30ef9b28b1699","3b8b958253544e6e9cc6f381e0b1391d","ab08ed2665a6471984120951fe8cd4c1","00a6381091414c6fa2d241fa870ad716","e9ecc907a00144f3a92ca27a0299535f","39ca89d519b24b019ca8067a3f700306","93a0f07cc876423b89cf96ff99437052","b2b1948c48c8481e9c5c23f1bf7309fd","ec322aac9c774a05aaca6aa820f96d2d","14eec88880974c688540d695baa190c0","4c287c2a7c5449f3a6ad173f5cfdfc34","0974dfe96a5147d89fd5269384dbf5fc","442fdc01a10e4523b27acd59818e5e7e","62e6121c3cf747cea11a0746d4d25062","3332fc1f3d2240cba5af6e762e465d27","d92a35d237094225969187b16d3ad169","64b017d5880c4dcfae778d8bea70ce1c","fc7d3fe597bb44969dfa2d6ad47e07f7","8371815a52f94b269b784746e25b98b5","adb8b3a6964b402ca14b4b841f4bac76","d27266681d8546999341acfa83732272","de7b0a0c7803434f9b49c3d703dd1926","af04f4b9659543b193f8cd5919f4b6f4","48029c9f723f469e809d86b02a32d325","b0608548001f403ea943fea204248e74","80151a82087f43e5b608ce3f8bc74b7f","c45971d78eb94ca58cfa49017fe045b3","efea23c666974063a1f661c8c828bb33","d92a5f54e2404a03bbf6694d536afc60","a72583c6064348cf997ca86664fb31bd","778d0f7423ba4821983b017dfaad0c2d","f0b23253a1404f2eb3bde8dbff6c89a0","ad8f26abed9b4b7496ff457242315328","4fbbbd584ca843df9655d2d11b085c2f","8ea7084171b94b3abce2e3b7f3c400a7","3c975e6a55bd406fab6b254220951952","4d9e12cbc93f495bbbb31afa8b87f22e","f8b2b9499c7544ec8e0cf6f181a403f0"]},"executionInfo":{"elapsed":2953,"status":"error","timestamp":1757025108365,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"},"user_tz":420},"id":"l7B04N-QzaG4","outputId":"de4d8325-61bc-4509-faef-fa82193eba1f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8d19928c4424e218e235d46a9d95e22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd2d80e62ea144dbb77a1ad6e4fd3f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39ca89d519b24b019ca8067a3f700306"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64b017d5880c4dcfae778d8bea70ce1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efea23c666974063a1f661c8c828bb33"}},"metadata":{}},{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'SequenceSummary' from 'transformers.modeling_utils' (/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3496999126.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt2\"\u001b[0m \u001b[0;31m# Replace with your desired model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimm_backbone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimmBackboneConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimmBackboneConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out_features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mname_to_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_models\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0marchitectures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"architectures\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0march\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marchitectures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0march\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_to_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mname_to_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    805\u001b[0m         mapping_items = [\n\u001b[1;32m    806\u001b[0m             (\n\u001b[0;32m--> 807\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__name__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_config_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reverse_config_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    731\u001b[0m         )\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class_with_generation_mixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mTokenClassifierOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceSummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_pruneable_heads_and_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_conv1d_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m from ...utils import (\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'SequenceSummary' from 'transformers.modeling_utils' (/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# Sample workload\n","# Watch the GPU working in Terminal:\n","#   watch -n 1 nvidia-smi\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import accelerate\n","import torch\n","\n","# Move the model to the GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_name = \"gpt2\" # Replace with your desired model\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name, device_map=device)\n","\n","\n","input_text = \"Hello, my name is\"\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device) # Move input to GPU\n","output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","print(generated_text)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e8d19928c4424e218e235d46a9d95e22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49e82cf4035d44fea00a917d9a675547","IPY_MODEL_d232660189254beba0d638b21a988f7c","IPY_MODEL_da467badf3bd4787ab947e07e388ebdd"],"layout":"IPY_MODEL_d0df6519f1814c9bb71581151b3a5782"}},"49e82cf4035d44fea00a917d9a675547":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_264b4617ac3047febb9c61181e9a5f1d","placeholder":"​","style":"IPY_MODEL_40dc4e2c43644df4b906014df5b219d3","value":"tokenizer_config.json: 100%"}},"d232660189254beba0d638b21a988f7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bee7682c98341dd99e7c12b18f8d613","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf2fe47a2c6a4f988063ff54a3c073c4","value":26}},"da467badf3bd4787ab947e07e388ebdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16c1f2839fbf47db9ff23ae02eca20f2","placeholder":"​","style":"IPY_MODEL_8a75bdbf23024c159fb96e84d2adfcce","value":" 26.0/26.0 [00:00&lt;00:00, 2.38kB/s]"}},"d0df6519f1814c9bb71581151b3a5782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"264b4617ac3047febb9c61181e9a5f1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40dc4e2c43644df4b906014df5b219d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bee7682c98341dd99e7c12b18f8d613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf2fe47a2c6a4f988063ff54a3c073c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16c1f2839fbf47db9ff23ae02eca20f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a75bdbf23024c159fb96e84d2adfcce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd2d80e62ea144dbb77a1ad6e4fd3f43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f42b25c86774cf8a783351bd34cee89","IPY_MODEL_be13bb353c5c47418ce36b476e5cdb09","IPY_MODEL_0b4b22c170514feb89959cc55a07bd76"],"layout":"IPY_MODEL_a87b8c82126d467583058e95d78859d8"}},"4f42b25c86774cf8a783351bd34cee89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4aa90b6ee9b448cfa634cf49d92e3513","placeholder":"​","style":"IPY_MODEL_ba71a7ab4662410f92f30ef9b28b1699","value":"config.json: 100%"}},"be13bb353c5c47418ce36b476e5cdb09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b8b958253544e6e9cc6f381e0b1391d","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab08ed2665a6471984120951fe8cd4c1","value":665}},"0b4b22c170514feb89959cc55a07bd76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00a6381091414c6fa2d241fa870ad716","placeholder":"​","style":"IPY_MODEL_e9ecc907a00144f3a92ca27a0299535f","value":" 665/665 [00:00&lt;00:00, 60.2kB/s]"}},"a87b8c82126d467583058e95d78859d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aa90b6ee9b448cfa634cf49d92e3513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba71a7ab4662410f92f30ef9b28b1699":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b8b958253544e6e9cc6f381e0b1391d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab08ed2665a6471984120951fe8cd4c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00a6381091414c6fa2d241fa870ad716":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9ecc907a00144f3a92ca27a0299535f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39ca89d519b24b019ca8067a3f700306":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93a0f07cc876423b89cf96ff99437052","IPY_MODEL_b2b1948c48c8481e9c5c23f1bf7309fd","IPY_MODEL_ec322aac9c774a05aaca6aa820f96d2d"],"layout":"IPY_MODEL_14eec88880974c688540d695baa190c0"}},"93a0f07cc876423b89cf96ff99437052":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c287c2a7c5449f3a6ad173f5cfdfc34","placeholder":"​","style":"IPY_MODEL_0974dfe96a5147d89fd5269384dbf5fc","value":"vocab.json: 100%"}},"b2b1948c48c8481e9c5c23f1bf7309fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_442fdc01a10e4523b27acd59818e5e7e","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62e6121c3cf747cea11a0746d4d25062","value":1042301}},"ec322aac9c774a05aaca6aa820f96d2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3332fc1f3d2240cba5af6e762e465d27","placeholder":"​","style":"IPY_MODEL_d92a35d237094225969187b16d3ad169","value":" 1.04M/1.04M [00:00&lt;00:00, 6.08MB/s]"}},"14eec88880974c688540d695baa190c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c287c2a7c5449f3a6ad173f5cfdfc34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0974dfe96a5147d89fd5269384dbf5fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"442fdc01a10e4523b27acd59818e5e7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62e6121c3cf747cea11a0746d4d25062":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3332fc1f3d2240cba5af6e762e465d27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d92a35d237094225969187b16d3ad169":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64b017d5880c4dcfae778d8bea70ce1c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc7d3fe597bb44969dfa2d6ad47e07f7","IPY_MODEL_8371815a52f94b269b784746e25b98b5","IPY_MODEL_adb8b3a6964b402ca14b4b841f4bac76"],"layout":"IPY_MODEL_d27266681d8546999341acfa83732272"}},"fc7d3fe597bb44969dfa2d6ad47e07f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de7b0a0c7803434f9b49c3d703dd1926","placeholder":"​","style":"IPY_MODEL_af04f4b9659543b193f8cd5919f4b6f4","value":"merges.txt: 100%"}},"8371815a52f94b269b784746e25b98b5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48029c9f723f469e809d86b02a32d325","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0608548001f403ea943fea204248e74","value":456318}},"adb8b3a6964b402ca14b4b841f4bac76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80151a82087f43e5b608ce3f8bc74b7f","placeholder":"​","style":"IPY_MODEL_c45971d78eb94ca58cfa49017fe045b3","value":" 456k/456k [00:00&lt;00:00, 2.75MB/s]"}},"d27266681d8546999341acfa83732272":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de7b0a0c7803434f9b49c3d703dd1926":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af04f4b9659543b193f8cd5919f4b6f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48029c9f723f469e809d86b02a32d325":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0608548001f403ea943fea204248e74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80151a82087f43e5b608ce3f8bc74b7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c45971d78eb94ca58cfa49017fe045b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efea23c666974063a1f661c8c828bb33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d92a5f54e2404a03bbf6694d536afc60","IPY_MODEL_a72583c6064348cf997ca86664fb31bd","IPY_MODEL_778d0f7423ba4821983b017dfaad0c2d"],"layout":"IPY_MODEL_f0b23253a1404f2eb3bde8dbff6c89a0"}},"d92a5f54e2404a03bbf6694d536afc60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad8f26abed9b4b7496ff457242315328","placeholder":"​","style":"IPY_MODEL_4fbbbd584ca843df9655d2d11b085c2f","value":"tokenizer.json: 100%"}},"a72583c6064348cf997ca86664fb31bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ea7084171b94b3abce2e3b7f3c400a7","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c975e6a55bd406fab6b254220951952","value":1355256}},"778d0f7423ba4821983b017dfaad0c2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d9e12cbc93f495bbbb31afa8b87f22e","placeholder":"​","style":"IPY_MODEL_f8b2b9499c7544ec8e0cf6f181a403f0","value":" 1.36M/1.36M [00:00&lt;00:00, 8.35MB/s]"}},"f0b23253a1404f2eb3bde8dbff6c89a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad8f26abed9b4b7496ff457242315328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fbbbd584ca843df9655d2d11b085c2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ea7084171b94b3abce2e3b7f3c400a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c975e6a55bd406fab6b254220951952":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d9e12cbc93f495bbbb31afa8b87f22e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8b2b9499c7544ec8e0cf6f181a403f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5cd8d18a7164378b5a5c7efae400eb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e14b3f7cfa87422fbddad20d4b55d80c","IPY_MODEL_325b883264cb44638d780338b1bd4a09","IPY_MODEL_b3dd2ac7baf742e681c2fd1a673ea2a5"],"layout":"IPY_MODEL_1b360fcd0b314b0b8db7f300fc25d329"}},"e14b3f7cfa87422fbddad20d4b55d80c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cef4e8b6ffb34e119845b4a1da1456b7","placeholder":"​","style":"IPY_MODEL_0297d8d3ca2844c29edc74b3aa8e73de","value":"Loading checkpoint shards: 100%"}},"325b883264cb44638d780338b1bd4a09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d439a2c791e04572b29105d33ec09c3d","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33fa48a9a84c4dd6bdde1d9159a65f5a","value":4}},"b3dd2ac7baf742e681c2fd1a673ea2a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbec4daeca3440bfb9b14c76b933bfec","placeholder":"​","style":"IPY_MODEL_45b1911ed6df4109b1a6588eef0c4552","value":" 4/4 [03:54&lt;00:00, 46.75s/it]"}},"1b360fcd0b314b0b8db7f300fc25d329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cef4e8b6ffb34e119845b4a1da1456b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0297d8d3ca2844c29edc74b3aa8e73de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d439a2c791e04572b29105d33ec09c3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33fa48a9a84c4dd6bdde1d9159a65f5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbec4daeca3440bfb9b14c76b933bfec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b1911ed6df4109b1a6588eef0c4552":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}