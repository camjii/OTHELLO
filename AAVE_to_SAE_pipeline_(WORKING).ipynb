{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"64e535ba137a4ac288a5917fd8ee6411":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_9a45862d615d4dd6a96aadb12563067d"}},"a82662bb7de04e5bb5c16ec8594afd90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82385d84d8534047a7df9edb680b8872","placeholder":"​","style":"IPY_MODEL_8af3b54982424edf9e6de2ac27a592a3","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"4ae80ae6fd604f458281f2eead31e60d":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_4cde14e280954c14bc39b56571bc1a65","placeholder":"​","style":"IPY_MODEL_2036d07887cf4eabb97fbc89a35dd75f","value":""}},"43313e1353484945b16e78db6419a760":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_dde51bf49e744f20a023bd6618e87e16","style":"IPY_MODEL_0cbf724a17dc4c49a589bc01f079ecbe","value":true}},"71b40138567040839050c1386cddc831":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_cee864cf950e4572b75c3095effa3d39","style":"IPY_MODEL_4c0173bd55654f14aaa97ad9959d5ee9","tooltip":""}},"7da63d2ed6ce49ce985941f5febd5129":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c47f278d79ac4902848ac501ee7943c9","placeholder":"​","style":"IPY_MODEL_8049f18197484511befd6b75cdc895e9","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"9a45862d615d4dd6a96aadb12563067d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"82385d84d8534047a7df9edb680b8872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8af3b54982424edf9e6de2ac27a592a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cde14e280954c14bc39b56571bc1a65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2036d07887cf4eabb97fbc89a35dd75f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dde51bf49e744f20a023bd6618e87e16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cbf724a17dc4c49a589bc01f079ecbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cee864cf950e4572b75c3095effa3d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c0173bd55654f14aaa97ad9959d5ee9":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"c47f278d79ac4902848ac501ee7943c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8049f18197484511befd6b75cdc895e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2a51956e2ea41aabc50d2f44b0a7237":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8531403e73f949f2acd6e72242aa6fb8","placeholder":"​","style":"IPY_MODEL_547f5d66ae7b477288c1d63d68964156","value":"Connecting..."}},"8531403e73f949f2acd6e72242aa6fb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"547f5d66ae7b477288c1d63d68964156":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"288109b1a1b84f8c8822a1b2f90445bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90514d38d2d74c99b34467db2dc4ffbb","IPY_MODEL_564b86411d7d4bac844ab05a7f6a4afe","IPY_MODEL_79496b0fd82b4f75bc43b81f86e7994d"],"layout":"IPY_MODEL_6e2ee57427a2420b98631d80fbc3ff33"}},"90514d38d2d74c99b34467db2dc4ffbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8208e04849d5429ca5a0c650d8c990c8","placeholder":"​","style":"IPY_MODEL_8ff87632e40b400aa25a134eb5ac5b4b","value":"Loading checkpoint shards:   0%"}},"564b86411d7d4bac844ab05a7f6a4afe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_8694df5a618e44ba94163644f6427328","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6dfe1643d0c84db794fdf85aa9048d71","value":0}},"79496b0fd82b4f75bc43b81f86e7994d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d21bbde4e434539a72d5ab9e9c86623","placeholder":"​","style":"IPY_MODEL_e49c541a79e441f2a0acebfd4bb77aed","value":" 0/4 [00:34&lt;?, ?it/s]"}},"6e2ee57427a2420b98631d80fbc3ff33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8208e04849d5429ca5a0c650d8c990c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ff87632e40b400aa25a134eb5ac5b4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8694df5a618e44ba94163644f6427328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dfe1643d0c84db794fdf85aa9048d71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d21bbde4e434539a72d5ab9e9c86623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e49c541a79e441f2a0acebfd4bb77aed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## AAVE translation task"],"metadata":{"id":"1gUpcANx0OGd"}},{"cell_type":"markdown","source":["We could use this paper: https://aclanthology.org/2023.nlrse-1.1.pdf as a benchmark perhaps\n","\n","Or this one https://arxiv.org/pdf/2405.06545"],"metadata":{"id":"_0PT5ZLk0U2S"}},{"cell_type":"markdown","source":["#Drive Mounting"],"metadata":{"id":"z_52h-s30WxN"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"LicS7NqV0H9n","colab":{"base_uri":"https://localhost:8080/","height":54,"referenced_widgets":["64e535ba137a4ac288a5917fd8ee6411","a82662bb7de04e5bb5c16ec8594afd90","4ae80ae6fd604f458281f2eead31e60d","43313e1353484945b16e78db6419a760","71b40138567040839050c1386cddc831","7da63d2ed6ce49ce985941f5febd5129","9a45862d615d4dd6a96aadb12563067d","82385d84d8534047a7df9edb680b8872","8af3b54982424edf9e6de2ac27a592a3","4cde14e280954c14bc39b56571bc1a65","2036d07887cf4eabb97fbc89a35dd75f","dde51bf49e744f20a023bd6618e87e16","0cbf724a17dc4c49a589bc01f079ecbe","cee864cf950e4572b75c3095effa3d39","4c0173bd55654f14aaa97ad9959d5ee9","c47f278d79ac4902848ac501ee7943c9","8049f18197484511befd6b75cdc895e9","b2a51956e2ea41aabc50d2f44b0a7237","8531403e73f949f2acd6e72242aa6fb8","547f5d66ae7b477288c1d63d68964156"]},"executionInfo":{"status":"ok","timestamp":1759209029188,"user_tz":420,"elapsed":5889,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}},"outputId":"4e90906c-3440-429b-b36e-857a4280001d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64e535ba137a4ac288a5917fd8ee6411"}},"metadata":{}}],"source":["from huggingface_hub import login\n","import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/drive/Shareddrives/Algoverse_KSAC/hf_cache\" #stores model\n","os.environ[\"HF_HOME\"] = \"/content/drive/Shareddrives/Algoverse_KSAC/hf_home\"  # stores logins\n","\n","# hf_token = YOUR_TOKEN_HERE\n","\n","login()\n"]},{"cell_type":"markdown","source":["#Model Loading (DO NOT RUN)"],"metadata":{"id":"ykxKv5o30a9J"}},{"cell_type":"code","source":["# from transformers import AutoTokenizer, AutoModelForCausalLM\n","# import os\n","\n","# model_id = \"Qwen/Qwen3-8B\"\n","# save_path = \"/content/drive/Shareddrives/Algoverse_KSAC/hf_models/Qwen/Qwen3-8B\"\n","# os.makedirs(save_path, exist_ok=True)\n","\n","# # Download from hub\n","# tokenizer = AutoTokenizer.from_pretrained(model_id)\n","# model = AutoModelForCausalLM.from_pretrained(\n","#     model_id,\n","#     dtype=\"auto\", #For weight loading\n","#     device_map=\"auto\"\n","# )\n","\n","# # Save tokenizer + model as a single file\n","# tokenizer.save_pretrained(save_path)\n","# model.save_pretrained(\n","#     save_path,\n","#     safe_serialization=True, #Using .safetensors\n","# )\n","\n","# print(\"Model and tokenizer saved into:\", save_path)\n"],"metadata":{"id":"ktbjxVGf0f2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run this cell to purge GPU memory\n","\n","import gc\n","import torch\n","\n","# Delete model and tokenizer objects\n","try:\n","  del model\n","except:\n","  pass\n","\n","try:\n","  del tokenizer\n","except:\n","  pass\n","\n","# Run Python's garbage collector\n","gc.collect()\n","\n","# Clear CUDA cache\n","if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","print(\"GPU memory should now be purged.\")\n","\n","# Verify\n","!nvidia-smi"],"metadata":{"id":"mtCmDwhY0hub"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model Reloading\n","\n","Load model from save_path"],"metadata":{"id":"-ULuYGKF0kwH"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","save_path = \"/content/drive/Shareddrives/Algoverse_KSAC/hf_models/Qwen/Qwen3-8B\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(save_path, local_files_only=True)\n","model = AutoModelForCausalLM.from_pretrained(\n","    save_path,\n","    local_files_only=True,\n","    dtype=\"auto\",\n","    device_map=\"auto\"\n",")\n","\n","print(\"Reloaded model successfully\")\n","print(f\"model.device = {model.device}\") #Verifying device\n"],"metadata":{"id":"MM9E9jud0uSN","colab":{"base_uri":"https://localhost:8080/","height":478,"referenced_widgets":["288109b1a1b84f8c8822a1b2f90445bb","90514d38d2d74c99b34467db2dc4ffbb","564b86411d7d4bac844ab05a7f6a4afe","79496b0fd82b4f75bc43b81f86e7994d","6e2ee57427a2420b98631d80fbc3ff33","8208e04849d5429ca5a0c650d8c990c8","8ff87632e40b400aa25a134eb5ac5b4b","8694df5a618e44ba94163644f6427328","6dfe1643d0c84db794fdf85aa9048d71","1d21bbde4e434539a72d5ab9e9c86623","e49c541a79e441f2a0acebfd4bb77aed"]},"executionInfo":{"status":"error","timestamp":1759206472528,"user_tz":420,"elapsed":66511,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}},"outputId":"da4d0916-563e-49ff-b164-d6f6ec9b19d9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288109b1a1b84f8c8822a1b2f90445bb"}},"metadata":{}},{"output_type":"error","ename":"ValueError","evalue":"could not determine the shape of object type 'torch.storage.UntypedStorage'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-252616733.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5174\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5175\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5176\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5177\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5638\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5639\u001b[0;31m                 \u001b[0m_error_msgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisk_offload_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_offload_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_shard_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5640\u001b[0m                 \u001b[0merror_msgs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_error_msgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload_shard_file\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;31m# Skip it with fsdp on ranks other than 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_quantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m    947\u001b[0m             \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    811\u001b[0m                 )\n\u001b[1;32m    812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcasting_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasting_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'torch.storage.UntypedStorage'"]}]},{"cell_type":"markdown","source":["#Data Loading"],"metadata":{"id":"HiB9tROV4IhZ"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"GbhVOQMj5pcx","executionInfo":{"status":"ok","timestamp":1759206880576,"user_tz":420,"elapsed":15,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv(\"/content/drive/Shareddrives/Algoverse_KSAC/dilemma_ab_aave_only_v2.csv\")\n","\n","data.drop(\"QID\",axis =1, inplace=True)\n","\n","data_list = data['Question'].tolist()\n","\n"],"metadata":{"id":"Oz4KP5Ld4qKD","executionInfo":{"status":"ok","timestamp":1759208552736,"user_tz":420,"elapsed":46,"user":{"displayName":"Cameron Kruger","userId":"13108230718887433325"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["#Running Inference"],"metadata":{"id":"ri0RsQOM0zAn"}},{"cell_type":"code","source":["# from transformers import pipeline\n","from transformers.generation.utils import GenerationMixin\n"],"metadata":{"id":"EPqXSbQb0109"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inference on already-loaded model\n","\n","data_list = data_list[:30]\n","def translate(data_list):\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": (\n","\n","                \"You are a strict translation engine.\"\n","                \"You MUST only output the translated SAE (Standard American English) questions.\"\n","                \"Do not explain, do not reason, do not add tags or extra text.\"\n","                \"Only return the final grammatically correct questions, nothing else.\"\n","\n","\n","                \"Examples: \"\n","                \"AAVE: Who be Einstein's ol' lady? \"\n","                \"SAE: Who was Einstein's wife? \"\n","                \"AAVE: When Obama come in the world? \"\n","                \"SAE: When was Obama born? \"\n","                \"AAVE: Where King Jr. do that 'I got a dream' speech at? \"\n","                \"SAE: Where did Martin Luther King Jr. give his 'I Have a Dream' speech? \"\n","                \"AAVE: What year Mandela start runnin' South Africa, and how long he stay holdin' that seat? \"\n","                \"SAE: In what year did Mandela become the President of South Africa, and how long did he remain in office? \"\n","                \"Remember: ONLY output the translated SAE questions, line by line, with no commentary.\"\n","            ),\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": f\"Transform these incomplete questions into complete, grammatically perfect SAE. {' '.join(data_list[:30])}\"  #Joining a list into a string\n","        }\n","    ]\n","\n","    inputs = tokenizer.apply_chat_template(\n","        messages,\n","        add_generation_prompt=True,\n","        tokenize=True,\n","        return_dict=True,\n","        return_tensors=\"pt\",\n","        enable_thinking=False\n","    ).to(model.device)\n","\n","    outputs = model.generate(**inputs, max_new_tokens=2600, do_sample=False, temperature=0)  #Increasing the temperature, and only considering tokens that make up 90% of probability (p = prob)\n","\n","    # dummy = outputs[0][inputs[\"input_ids\"].shape[-1]:]\n","\n","    output_answer = tokenizer.decode(\n","        outputs[0][inputs[\"input_ids\"].shape[-1]:],  # Slicing the length of the input tokens to get what comes after (Getting the length) (start:end)\n","        skip_special_tokens=True\n","    ).split('\\n')\n","\n","    # breakpoint()\n","    # import pdb; pdb.set_trace()\n","    return output_answer\n","\n","\n","\n","translated_data = pd.DataFrame({\"AAVE input\": data_list, \"SAE output\": translate(data_list)})\n","\n","file = translated_data.to_csv(\"translated_data.csv\")\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Lj2zNdHN02Jr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Evaluate Single Pair"],"metadata":{"id":"qPNPU8Zb1Co6"}},{"cell_type":"code","source":["# Inference on already-loaded model\n","\n","\n","def translate(question):\n","    messages = [\n","        {\n","            \"role\": \"system\",\n","            \"content\": (\n","\n","                \"You are a strict translation engine.\"\n","                \"You MUST only output the translated SAE (Standard American English) questions.\"\n","                \"Do not explain, do not reason, do not add tags or extra text.\"\n","                \"Only return the final grammatically correct questions, nothing else.\"\n","\n","\n","                \"Examples:\\n\"\n","                \"AAVE: Who be Einstein's ol' lady?\\n\"\n","                \"SAE: Who was Einstein's wife?\\n\"\n","                \"AAVE: When Obama come in the world?\\n\"\n","                \"SAE: When was Obama born?\\n\\n\"\n","                \"AAVE: Where King Jr. do that 'I got a dream' speech at?\\n\"\n","                \"SAE: Where did Martin Luther King Jr. give his 'I Have a Dream' speech?\\n\\n\"\n","                \"AAVE: What year Mandela start runnin' South Africa, and how long he stay holdin' that seat?\\n\"\n","                \"SAE: In what year did Mandela become the President of South Africa, and how long did he remain in office?\\n\\n\"\n","                \"Remember: ONLY output the translated SAE questions, line by line, with no commentary.\"\n","            ),\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": f\"Transform this question into complete, grammatically perfect SAE. {question}\"  #Joining a list into a string\n","        }\n","    ]\n","\n","    inputs = tokenizer.apply_chat_template(\n","        messages,\n","        add_generation_prompt=True,\n","        tokenize=True,\n","        return_dict=True,\n","        return_tensors=\"pt\",\n","        enable_thinking=False\n","    ).to(model.device)\n","\n","    outputs = model.generate(**inputs, max_new_tokens=300, do_sample=False, temperature=0)  #Increasing the temperature, and only considering tokens that make up 90% of probability (p = prob)\n","\n","    # dummy = outputs[0][inputs[\"input_ids\"].shape[-1]:]\n","\n","    output_answer = tokenizer.decode(\n","        outputs[0][inputs[\"input_ids\"].shape[-1]:],  # Slicing the length of the input tokens to get what comes after (Getting the length) (start:end)\n","        skip_special_tokens=True\n","    ).split('\\n')\n","\n","    # breakpoint()\n","    # import pdb; pdb.set_trace()\n","    return output_answer\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"0lYl1FlO1CTS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Bart Score evaluation"],"metadata":{"id":"thXqTY0g1XOz"}},{"cell_type":"code","source":["import sys\n","import numpy as np"],"metadata":{"id":"jkhWVLQd1bXH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Install BLEURT first"],"metadata":{"id":"pgd56VpQ1a3i"}},{"cell_type":"code","source":["!pip install tensorflow>=2.3.0\n","!pip install tensorflow-text>=2.3.0\n","!git clone https://github.com/google-research/bleurt.git\n","!cd bleurt && python -m pip install .\n","sys.path.append('/content/bleurt')\n","!wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip\n","!unzip BLEURT-20.zip\n","\n"],"metadata":{"id":"7ldVf8hW1gdA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Install BARTScore"],"metadata":{"id":"oqmFVQPl1jSA"}},{"cell_type":"code","source":["\n","!git clone -q https://github.com/neulab/BARTScore.git\n","sys.path.append(\"/content/BARTScore\")\n","!pip -q install \"transformers>=4.40,<4.47\" sentencepiece accelerate torch tqdm --upgrade\n"],"metadata":{"id":"Vy_YXbFZ1nhr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from bart_score import BARTScorer\n","from bleurt import score\n","\n"],"metadata":{"id":"Ek9T0Rlr1o6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bart_scorer = BARTScorer(device='cuda', checkpoint='facebook/bart-large')\n","bleurt_scorer = score.BleurtScorer(\"./BLEURT-20\")"],"metadata":{"id":"lPHtgS_b1qT3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#code up"],"metadata":{"id":"bZhha_B41sCQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_multiple_pairs(inputs, outputs):\n","\n","    if len(inputs) != len(outputs):\n","        raise ValueError(\"Lists must be the same length\")\n","\n","\n","    results = []\n","    for i in range(len(inputs)):\n","        aave_text = inputs[i]\n","        sae_text = outputs[i]\n","        bart_score_backward = bart_scorer.score([sae_text], [aave_text], batch_size=1)\n","\n","        results.append({'bart_score_backward': bart_score_backward})\n","\n","        results_df = pd.DataFrame(results)\n","\n","    return results_df\n","\n","\n","inputs = translated_data['AAVE input'].to_list()\n","outputs = translated_data['SAE output'].to_list()\n","\n","results_df = evaluate_multiple_pairs(inputs, outputs)\n","\n","\n"],"metadata":{"id":"za-kXAAr1ue-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_results = pd.concat([translated_data, results_df], axis=1)\n","total_results.head(10)"],"metadata":{"id":"uFahDIMq2cb_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Judge LLM (WIP)"],"metadata":{"id":"U0VX-DcP2mnT"}},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=\"YOUR_KEY_HERE\")\n","\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": \"Evaluate the accuracy of the shown translation from AAVE to SAE. Do not provide a written explanation. Only provide a score from 0-100. If there is even any trace of missing semantic value, deduct from the total score\"},\n","\n","    {\"role\": \"user\", \"content\": \"Who be Einstein's ol' lady?\"},\n","    {\"role\": \"assistant\", \"content\": \"Who was Einstein's wife?\"},\n","\n","    {\"role\": \"user\", \"content\": \"When Obama come in the world?\"},\n","    {\"role\": \"assistant\", \"content\": \"When was Obama born?\"},\n","\n","    {\"role\": \"user\", \"content\": \"Where King Jr. do that 'I got a dream' speech at?\"},\n","    {\"role\": \"assistant\", \"content\": \"Where did Martin Luther King Jr. give his 'I Have a Dream' speech?\"},\n","\n","    {\"role\": \"user\", \"content\": \"What year Mandela start runnin’ South Africa, and how long he stay holdin’ that seat?\"},\n","    {\"role\": \"assistant\", \"content\": \"In what year did Mandela become the President of South Africa, and how long did he remain in office?\"},\n","\n","    #{\"role\": \"user\", \"content\": \"What spaceship took the first man round Earth, what his name was, and what year that go down?\"},\n","    #{\"role\": \"assistant\", \"content\": \"Which spacecraft carried the first human to orbit Earth, what was the astronaut’s name, and what year did this mission occur?\"},\n","\n","    {\"role\": \"user\", \"content\": \" AAVE: Who be the first man to step on the moon, and what year that happen? SAE: Who was the first man to step on the moon, and what year did he step on the moon?\"},\n","\n","]\n","\n","#\n","completion = client.chat.completions.create(\n","    model=\"gpt-4.1\",\n","    messages=messages,\n","    n=1,\n","    temperature=0\n",")\n","\n","score = completion.choices[0].message.content\n","print(score)\n","\n"],"metadata":{"id":"JjsiqmVG2o8w"},"execution_count":null,"outputs":[]}]}